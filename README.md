# GabGuard â€“ Uruchamianie serwera 

## ğŸ“ Utworzenie wymaganych katalogÃ³w

```bash
mkdir C:\data\db
```

---

## ğŸ“¦ PrzejÅ›cie do katalogu

```bash
cd .\gabguard-server\
```

---


## â–¶ï¸ Uruchomienie aplikacji

1. Aktywuj Å›rodowisko wirtualne:

```bash
.\.venv\Scripts\activate
```

2. WÅ‚Ä…cz MongoDB (lokalnie)(inny terminal):

```bash
c:\mongodb\bin\mongod.exe
```

3. Instalacja zaleÅ¼noÅ›ci

```bash
pip install -r requirements.txt
```

4. Uruchom backend FastAPI:

```bash
uvicorn main:app --reload
```

---

## ğŸ“ Notatki

- Dokumentacja API po uruchomieniu dostÄ™pna pod `http://127.0.0.1:8000/docs`.

---

## âš™ï¸ Endpointy API

PoniÅ¼ej znajduje siÄ™ lista dostÄ™pnych endpointÃ³w API wraz z opisem ich funkcjonalnoÅ›ci i struktury zwracanych danych.

1. `/analyze_text` - **Analiza Tekstu**

Ten endpoint sÅ‚uÅ¼y do analizy dostarczonego tekstu.

**Metoda**: POST

**Zapytanie**: Tekst do analizy przesyÅ‚any jest jako plaintext w ciele Å¼Ä…dania (request body).

**PrzykÅ‚ad zapytania (JSON)**:
```JSON
{"text": "PrzykÅ‚adowy tekst do analizy."}
```

**Zwracane dane (JSON)**:
```JSON
{
  "user_id": "string",
  "text": "string",
  "toxicity_score": 0
}
```
* `user_id`: Identyfikator uÅ¼ytkownika, ktÃ³ry wysÅ‚aÅ‚ tekst.
* `text`: Przetworzony tekst.
* `toxicity_score`: WspÃ³Å‚czynnik toksycznoÅ›ci tekstu. WartoÅ›Ä‡ `0` oznacza brak toksycznoÅ›ci. W przypadku wystÄ…pienia bÅ‚Ä™du podczas analizy przez model AI, zwracana jest wartoÅ›Ä‡ `-1`.

2. `/analyze_audio` - **Analiza Audio**

Ten endpoint umoÅ¼liwia analizÄ™ plikÃ³w audio.

**Metoda**: POST

**Zapytanie**: Plik audio (w formacie .mp3 lub .wav) przesyÅ‚any jest jako plik w formularzu (multipart/form-data).

**Zwracane dane (JSON)**:
```JSON
{
  "user_id": "string",  
  "transcription": "string",  
  "toxicity_score": 0
}
```
* `user_id`: Identyfikator uÅ¼ytkownika, ktÃ³ry przesÅ‚aÅ‚ plik audio.
* `transcription`: Transkrypcja zawartoÅ›ci pliku audio na tekst.
* `toxicity_score`: WspÃ³Å‚czynnik toksycznoÅ›ci transkrybowanego tekstu. WartoÅ›Ä‡ `0` oznacza brak toksycznoÅ›ci. W przypadku wystÄ…pienia bÅ‚Ä™du podczas analizy przez model * AI, zwracana jest wartoÅ›Ä‡ `-1`.

3. `/analyze-file/` - **Analiza PlikÃ³w**

Ten endpoint sÅ‚uÅ¼y do ogÃ³lnej analizy plikÃ³w rÃ³Å¼nego typu.

**Metoda**: POST

**Zapytanie**: Dowolny typ pliku przesyÅ‚any jest jako plik w formularzu (multipart/form-data).

**Zwracane dane (JSON)**:
```JSON
{
  "user_id": "string",  
  "description": "string",  
  "toxicity_score": 0
}
```
* `user_id`: Identyfikator uÅ¼ytkownika, ktÃ³ry przesÅ‚aÅ‚ plik.
* `description`: Opis zawartoÅ›ci pliku lub wyekstrahowany tekst (jeÅ›li to moÅ¼liwe).
* `toxicity_score`: WspÃ³Å‚czynnik toksycznoÅ›ci wyekstrahowanego tekstu (jeÅ›li dotyczy). WartoÅ›Ä‡ `0` oznacza brak toksycznoÅ›ci. W przypadku wystÄ…pienia bÅ‚Ä™du podczas analizy przez model AI, zwracana jest wartoÅ›Ä‡ `-1`.

4. `/users/{user_id}/violations/recent` - **Generowanie Raportu NaruszeÅ„ UÅ¼ytkownika**

Ten endpoint generuje raport w formacie PDF dla konkretnego uÅ¼ytkownika.  DostÄ™pny jest dla administratorÃ³w systemu.

**Metoda**: GET

**Parametry** URL:

* `user_id`: Identyfikator uÅ¼ytkownika, dla ktÃ³rego ma zostaÄ‡ wygenerowany raport. NaleÅ¼y go umieÅ›ciÄ‡ bezpoÅ›rednio w Å›cieÅ¼ce URL, np. `/users/123/violations/recent`.

**Zwracane dane**:

Plik PDF zawierajÄ…cy raport naruszeÅ„ dla danego uÅ¼ytkownika.

### WaÅ¼ne:

W przypadku wszystkich endpointÃ³w analizujÄ…cych tekst ( `/analyze_text`, `/analyze_audio`, `/analyze-file/`), jeÅ¼eli wartoÅ›Ä‡ `toxicity_score` wynosi `-1`, oznacza to, Å¼e wystÄ…piÅ‚ bÅ‚Ä…d podczas przetwarzania i analizy tekstu/pliku przez model sztucznej inteligencji.